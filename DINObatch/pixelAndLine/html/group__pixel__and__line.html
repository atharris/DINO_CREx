<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Batch Filter Functions: pixelLineBatch - pixel and line measurements generation</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/SVG"],
});
</script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="Basilisk-Logo.jpg"/></td>
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">Batch Filter Functions
   &#160;<span id="projectnumber">0.1.5</span>
   </div>
   <div id="projectbrief">Functions shared amongst differing batch filters</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
</div><!-- top -->
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">pixelLineBatch - pixel and line measurements generation</div>  </div>
</div><!--header-->
<div class="contents">

<p>The module for the creation of pixel and line data.  
<a href="#details">More...</a></p>
<p>The module for the creation of pixel and line data. </p>
<h1><a class="anchor" id="overview"></a>
Overview </h1>
<h2>Purpose </h2>
<p>This script contains two exportable functions as well as four internal functions. The primary goal of the module is to contain a reference observation function and observation-state mapping matrix function that take inputs and outputs as dictated by this software suite's batch functions.</p>
<h2>Contents </h2>
<p>The following exportable functions are contained in this module:</p>
<ul>
<li><code>fncH</code></li>
<li><code>fncG</code></li>
</ul>
<p><code>fncH</code> is the function that computes the method for computing the observation-state mapping matrix, while <code>fncG</code> computes the observed quantities for the respective inputs. This language is chosen for the latter due to the fact that although the intended use of <code>fncG.py</code> is to provide reference measurements for the batch filter, it is possible that it could be used to generate a data set representing "true" measurements. It would then be up to the operator to provide appropriate inputs for either case.</p>
<p>The following internal functions are contained in this module:</p>
<ul>
<li><code>I_to_TC</code></li>
<li><code>rot1</code></li>
<li><code>rot2</code></li>
<li><code>rot3</code></li>
</ul>
<p>All four functions are linear transformations, with <code>I_to_TV</code> calling the remaining three rotation functions. Specifically, <code>I_to_TV</code> creates an inertial to camera coordinate transformation matrix, while the other functions compute rotation matrices for a 3-D coordinate system.</p>
<p>As with other modules in the state estimation nav filter, there is a reliance on the <code>extras</code> dictionary to pass through parameters to various functions. It is noted that the <code>extras</code> dictionary should never be an output from a function.</p>
<h1>The Code </h1>
<h2><code>fncH</code> </h2>
<p><code>fncH</code> is a function that produces the observation-state mapping matrix (H) used within a batch filter. The following is a table of inputs and associated brief descriptions:</p>
<table class="doxtable">
<tr>
<th>Name </th><th>Description </th><th>Size/Type  </th></tr>
<tr>
<td>state </td><td>input state of the quantities of interest for each observation time </td><td>(N,d) numpy array </td></tr>
<tr>
<td>beaconStates </td><td>propagated beacon states </td><td>(N,6) numpy array </td></tr>
<tr>
<td>angles </td><td>reference attitude angles for each observation time</td><td>(N,3) numpy array </td></tr>
<tr>
<td>extras </td><td>dictionary of various parameters </td><td>dictionary </td></tr>
</table>
<p>The same is repeated for outputs:</p>
<table class="doxtable">
<tr>
<th>Name </th><th>Description </th><th>Size/Type  </th></tr>
<tr>
<td>H </td><td>observation-state mapping matrices for each time step </td><td>(2*N,6) numpy array </td></tr>
</table>
<p>The size of the output is determined from the fact that there are two rows of partials at each time. This is due to the fact that a pixel and line filter has two observation types.</p>
<p>The significant lines of code in this function are within a loop that counts the number of observations. At each iteration, the relative position vector between the selected beacon and spacecraft is calculated </p><div class="fragment"><div class="line"><span class="comment"># calculate the difference between the positions of the beacon and state</span></div><div class="line">positionDiff = selectedBeacon[0:3] - state[ii, 0:3]</div></div><!-- fragment --><p>This <code>positionDiff</code> is then used to calculate a unit pointing vector and its derivatives. </p><div class="fragment"><div class="line"><span class="comment"># create inertial unit pointing vector (A_hat_I)</span></div><div class="line">A_hat_I = positionDiff / rho</div><div class="line"></div><div class="line"><span class="comment"># partials of A_hat_I with respect to position components</span></div><div class="line">dA_IdX = np.array([ positionDiff[0]**2 / rho**3 - 1. / rho,\</div><div class="line">                    positionDiff[0] * positionDiff[1] / rho**3,\</div><div class="line">                    positionDiff[0] * positionDiff[2] / rho**3 ])</div><div class="line"></div><div class="line">dA_IdY = np.array([ positionDiff[1] * positionDiff[0] / rho**3,\</div><div class="line">                    positionDiff[1]**2 / rho**3 - 1. / rho,\</div><div class="line">                    positionDiff[1] * positionDiff[2] / rho**3 ])</div><div class="line"></div><div class="line">dA_IdZ = np.array([ positionDiff[2] * positionDiff[0] / rho**3,\</div><div class="line">                    positionDiff[2] * positionDiff[1] / rho**3,\</div><div class="line">                    positionDiff[2]**2 / rho**3 - 1. / rho ])</div></div><!-- fragment --><p>These values are transformed into the millimeter coordinates </p><div class="fragment"><div class="line"><span class="comment"># partials of millimeter frame with respect to state</span></div><div class="line">dMMdX = FoL * np.array( [ -1. / A_hat_TV[2]**2 * dA_TVdX[2] * A_hat_TV[0] +\</div><div class="line">                                       dA_TVdX[0] / A_hat_TV[2],\</div><div class="line">                -1. / A_hat_TV[2]**2 * dA_TVdX[2] * A_hat_TV[1] +\</div><div class="line">                                       dA_TVdX[1] / A_hat_TV[2]  ] )</div><div class="line"></div><div class="line">dMMdY = FoL * np.array( [ -1. / A_hat_TV[2]**2 * dA_TVdY[2] * A_hat_TV[0] +\</div><div class="line">                                       dA_TVdY[0] / A_hat_TV[2],\</div><div class="line">                -1. / A_hat_TV[2]**2 * dA_TVdY[2] * A_hat_TV[1] +\</div><div class="line">                                       dA_TVdY[1] / A_hat_TV[2]  ] )</div><div class="line"></div><div class="line">dMMdZ = FoL * np.array( [ -1. / A_hat_TV[2]**2 * dA_TVdZ[2] * A_hat_TV[0] +\</div><div class="line">                                       dA_TVdZ[0] / A_hat_TV[2],\</div><div class="line">                -1. / A_hat_TV[2]**2 * dA_TVdZ[2] * A_hat_TV[1] +\</div><div class="line">                                       dA_TVdZ[1] / A_hat_TV[2]  ] ) </div></div><!-- fragment --><p> The resulting values are a then a constant multiplication away from being the pointing vector derivatives in the camera frame.</p>
<h2><code>fncG</code> </h2>
<p><code>fncG</code> is a function that computes measurement data for each observation time. It relies on inputs similar to <code>fncH</code>. In the case of this module, the measurement data is pixel and line. Specifically:</p>
<table class="doxtable">
<tr>
<th>Name </th><th>Description </th><th>Size/Type  </th></tr>
<tr>
<td>state </td><td>input state of the quantities of interest for each observation time </td><td>(N,d) numpy array </td></tr>
<tr>
<td>beaconStates </td><td>propagated beacon states </td><td>(N,6) numpy array </td></tr>
<tr>
<td>angles </td><td>reference attitude angles for each observation time </td><td>(N,3) numpy array </td></tr>
<tr>
<td>extras </td><td>dictionary of various parameters </td><td>dictionary </td></tr>
</table>
<p>The same is repeated for outputs:</p>
<table class="doxtable">
<tr>
<th>Name </th><th>Description </th><th>Size/Type  </th></tr>
<tr>
<td>G </td><td>measurement data for each time step </td><td>(N,2) numpy array </td></tr>
</table>
<p>Due to the nature of the relationship between the H matrix and measurement generation, the code of <code>fncG</code> largely mirrors that of <code>fncH</code>. There is a significant when considering the fact that <code>fncH</code> effectively computes the derivatives of <code>fncG</code>. The measurement generation begins with computing the relative position <code>positionDiff</code>. For this function, however, the derivative of the pointing vector is never calculated. Therefore, the code consists of the calculation of the unit vector </p><div class="fragment"><div class="line"><span class="comment"># create inertial unit pointing vector (A_hat)</span></div><div class="line">Ahat_I = positionDiff / np.linalg.norm( positionDiff )</div></div><!-- fragment --><p>Followed by a rotation from inertial to camera and a conversion to millimeter coordinates </p><div class="fragment"><div class="line"><span class="comment"># rotate inertial pointing vector to camera (TV) frame</span></div><div class="line">Ahat_TV = np.dot( DCM_TVI, Ahat_I )</div><div class="line"></div><div class="line"><span class="comment"># convert TV frame to millimeter units</span></div><div class="line">x_mm = FoL / Ahat_TV[2] * Ahat_TV[0]</div><div class="line">y_mm = FoL / Ahat_TV[2] * Ahat_TV[1]</div></div><!-- fragment --><p>Millimeter is then converted to pixel and line by adding the resolution offset and multiplying by pixel width (for pixel units) and pixel height (for line units). </p><div class="fragment"><div class="line"><span class="comment"># convert millimeter to P&amp;L</span></div><div class="line">pixel = Kx * Dx * x_mm + p0</div><div class="line">line  = Ky * Dy * y_mm + l0</div></div><!-- fragment --><p> The pixel and line measurements are then stored in the G array for output</p>
<h2><code>rot#</code> </h2>
<p>The rotation matrices included in this module are typical 3-D coordinate rotation matrices in the 1-2-3 axis format. Therefore, the inputs and outputs are functionally similar for all three functions. The inputs are the appropriate attitude angle for the stated rotation direction:</p>
<table class="doxtable">
<tr>
<th>Name </th><th>Description </th><th>Size/Type  </th></tr>
<tr>
<td>angle </td><td>rotation angle, in radians, to be applied to the matrix formula </td><td>double </td></tr>
</table>
<p>The outputs are all numpy arrays calculated using the relevant rotation matrix equations:</p>
<table class="doxtable">
<tr>
<th>Name </th><th>Description </th><th>Size/Type  </th></tr>
<tr>
<td>matrixRot# </td><td>resulting rotation matrix </td><td>(3,3) numpy array </td></tr>
</table>
<p>These matrices are called in the intertia to camera coordinate transformation matrix function</p>
<h2><code>I_to_TV</code> </h2>
<p>The <code>I_to_TV</code> function constructs a transformation matrix for interial to the camera coordinate frame. This differs from the <code>rot#</code> functions as the input is an array of all three angles, which are then used as inputs to each rotation function individually:</p>
<table class="doxtable">
<tr>
<th>Name </th><th>Description </th><th>Size/Type  </th></tr>
<tr>
<td>angles </td><td>rotation angles, in radians </td><td>(3,) numpy array </td></tr>
</table>
<p>The output is an array that functions as a transformation matrix:</p>
<table class="doxtable">
<tr>
<th>Name </th><th>Description </th><th>Size/Type  </th></tr>
<tr>
<td>I_to_TV_matrix </td><td>inertial to camera transformation matrix </td><td>(3,3) numpy array </td></tr>
</table>
<p>This matrix is composed of a 1-2-3 rotation matrix application, as seen in the code: </p><div class="fragment"><div class="line">I_to_TV_matrix = np.dot( rot3( angles[0] ), \</div><div class="line">                np.dot( rot2( angles[1] ), rot1( angles[2] ) ) )</div></div><!-- fragment --> </div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Mon Dec 18 2017 11:32:16 for Batch Filter Functions by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.13
</small></address>
</body>
</html>
